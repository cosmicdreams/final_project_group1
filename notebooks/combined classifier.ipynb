{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "sheet_delimiter": true,
     "type": "MD"
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "# Importing all necessary libraries\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten, Dropout, Dense\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# What does our image data look like?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# A little bit of data exploration\n",
    "path = 'input/PokemonData'  # Path to directory which contains classes\n",
    "classes = os.listdir(path)  # List of all classes\n",
    "print(f'Total number of categories: {len(classes)}')\n",
    "\n",
    "# A dictionary which contains class and number of images in that class\n",
    "counts = {}\n",
    "for c in classes:\n",
    "    counts[c] = len(os.listdir(os.path.join(path, c)))\n",
    "\n",
    "print(f'Total number of images in dataset: {sum(list(counts.values()))}')\n",
    "\n",
    "# Number of images in each clsss plot\n",
    "fig = plt.figure(figsize=(25, 5))\n",
    "sns.lineplot(x=list(counts.keys()), y=list(counts.values())).set_title('Number of images in each class')\n",
    "plt.xticks(rotation=90)\n",
    "plt.margins(x=0)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's break our pokemon data into two halves.  Sending to many images to our classifier will make it take a long time.\n",
    "\n",
    "## First Half of pokemon images we have."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Sort our \"counts\" dictionary and selecting 5 classes with most number of images\n",
    "combined = sorted(counts.items(), key=lambda x: x[1], reverse=True)\n",
    "print(combined)\n",
    "\n",
    "# Taking only labels, it will come in handy in future\n",
    "combined = [i[0] for i in combined]\n",
    "print(combined)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Venusaur, Pikachu, Snorlax, Vaporeon and Scyther are the Pokemon that we have the most images for.  \n",
    "\n",
    "Next we'll attempt to remove images that won't process well."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = []  # List for images\n",
    "Y = []  # List for labels\n",
    "\n",
    "# Loop through all classes\n",
    "for c in classes:\n",
    "    # We take only classes that we defined in 'first_half' list\n",
    "    if c in combined:\n",
    "        dir_path = os.path.join(path, c)\n",
    "        label = combined.index(c)  # Our label is an index of class in 'first_half' list\n",
    "\n",
    "        # Reading, resizing and adding image and label to lists\n",
    "        for i in os.listdir(dir_path):\n",
    "            image = cv.imread(os.path.join(dir_path, i))\n",
    "\n",
    "            try:\n",
    "                resized = cv.resize(image, (96, 96))\n",
    "                X.append(resized)\n",
    "                Y.append(label)\n",
    "\n",
    "            # If we can't read image - we skip it\n",
    "            except:\n",
    "                print(os.path.join(dir_path, i), '[ERROR] can\\'t read the file')\n",
    "                continue\n",
    "\n",
    "print('DONE')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Counting appearances of each label in labels list\n",
    "obj = Counter(Y)\n",
    "\n",
    "# Plotting number of images in each class\n",
    "fig = plt.figure(figsize=(60, 5))\n",
    "sns.barplot(x=[combined[i] for i in obj.keys()], y=list(obj.values())).set_title('Number of images per pokemon')\n",
    "plt.margins(x=0)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Convert list with images to numpy array and reshape it \n",
    "X = np.array(X).reshape(-1, 96, 96, 3)\n",
    "\n",
    "# Scaling data in array\n",
    "X = X / 255.0\n",
    "\n",
    "# Convert labels to categorical format\n",
    "y = to_categorical(Y, num_classes=len(combined))\n",
    "\n",
    "# Splitting data to train and test datasets\n",
    "# I'll use these datasets only for training, for final predictions I'll use random pictures from internet\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, shuffle=True, random_state=666)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use data augmentation to provide even more images."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Defining ImageDataGenerator Instance\n",
    "datagen = ImageDataGenerator(rotation_range=45,  # Degree range for random rotations\n",
    "                             zoom_range=0.2,  # Range for random zoom\n",
    "                             horizontal_flip=True,  # Randomly flip inputs horizontally\n",
    "                             width_shift_range=0.15,  # Range for horizontal shift\n",
    "                             height_shift_range=0.15,  # Range for vertical shift\n",
    "                             shear_range=0.2)  # Shear Intensity\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# This piece of code can be used if you eant to look what your datagen doing with your images\n",
    "img = X[300]\n",
    "img = img.reshape([-1, 96, 96, 3])\n",
    "\n",
    "i = 0\n",
    "fig_check = plt.figure(figsize=(18, 8))\n",
    "\n",
    "for i, flow in enumerate(datagen.flow(img, batch_size=1)):\n",
    "    fig_check.add_subplot(2, 5, i + 1)\n",
    "    plt.imshow(np.squeeze(flow[:, :, ::-1]))\n",
    "    plt.axis('off')\n",
    "    i += 1\n",
    "    if i >= 10:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(combined)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Conv2D(32, 3, padding='same', activation='relu', input_shape=(96, 96, 3), kernel_initializer='he_normal'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, 3, padding='same', kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Conv2D(64, 3, padding='same', kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, 3, padding='same', kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Conv2D(128, 3, padding='same', kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256, 3, padding='same', kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Conv2D(256, 3, padding='same', kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(combined), activation='softmax'))\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('working/best_model_combined.hdf5', verbose=1, monitor='val_accuracy', save_best_only=True)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=60, validation_data=[X_test, y_test],\n",
    "                    steps_per_epoch=len(X_train) // 32, callbacks=[checkpoint])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot learning curves\n",
    "fig = plt.figure(figsize=(17, 4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(history.history['accuracy'], label='acc')\n",
    "plt.plot(history.history['val_accuracy'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(f'accuracy')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(f'loss')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Loading weights from best model\n",
    "model.load_weights('working/best_model_combined.hdf5')\n",
    "\n",
    "# Saving all model\n",
    "model.save('working/combined_model.hdf5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mewtwo = ['https://cdn.bulbagarden.net/upload/thumb/7/78/150Mewtwo.png/250px-150Mewtwo.png',\n",
    "          'https://cdn.vox-cdn.com/thumbor/sZPPvUyKyF97UEU-nNtVnC3LpF8=/0x0:1750x941/1200x800/filters:focal(878x316:1158x596)/cdn.vox-cdn.com/uploads/chorus_image/image/63823444/original.0.jpg',\n",
    "          'https://images-na.ssl-images-amazon.com/images/I/61j5ozFjJ0L._SL1024_.jpg']\n",
    "\n",
    "pikachu = [\n",
    "    'https://lh3.googleusercontent.com/proxy/DrjDlKlu9YonKbj3iNCJNJ3DGqzy9GjeXXSUv-TcVV4UN9PMCAM5yIkGLPG7wYo3UeA4sq5OmUWM8M6K5hy2KOAhf8SOL3zPH3axb2Xo3HX2XTU8M2xW4X6lVg=w720-h405-rw',\n",
    "    'https://johnlewis.scene7.com/is/image/JohnLewis/237525467']\n",
    "\n",
    "charmander = ['https://img.pokemondb.net/artwork/large/charmander.jpg',\n",
    "              'https://www.pokemoncenter.com/wcsstore/PokemonCatalogAssetStore/images/catalog/products/P5073/701-03990/P5073_701-03990_01.jpg',\n",
    "              'https://static.posters.cz/image/750/%D0%A7%D0%B0%D1%88%D0%BA%D0%B0/pokemon-charmander-glow-i72513.jpg']\n",
    "\n",
    "bulbasaur = ['https://img.pokemondb.net/artwork/large/bulbasaur.jpg',\n",
    "             'https://ae01.alicdn.com/kf/HTB1aWullxSYBuNjSsphq6zGvVXaR/Big-Size-55-CM-Plush-Toy-Squirtle-Bulbasaur-Charmander-Toy-Sleeping-Pillow-Doll-For-Kid-Birthday.jpg',\n",
    "             'https://cdn.bulbagarden.net/upload/thumb/f/f7/Bulbasaur_Detective_Pikachu.jpg/250px-Bulbasaur_Detective_Pikachu.jpg']\n",
    "\n",
    "squirtle = ['https://assets.pokemon.com/assets/cms2/img/pokedex/full/007.png',\n",
    "            'https://cdn.vox-cdn.com/thumbor/l4cKX7ZWargjs-zlxOSW2WZVgfI=/0x0:2040x1360/1200x800/filters:focal(857x517:1183x843)/cdn.vox-cdn.com/uploads/chorus_image/image/61498573/jbareham_180925_ply0802_0030.1537570476.jpg',\n",
    "            'https://thumbor.forbes.com/thumbor/960x0/https%3A%2F%2Fblogs-images.forbes.com%2Fdavidthier%2Ffiles%2F2018%2F07%2FSquirtle_Squad.jpg']\n",
    "\n",
    "test_df = [mewtwo, pikachu, charmander, bulbasaur, squirtle]\n",
    "test_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Lists to store our future data\n",
    "val_x = []\n",
    "val_y = []\n",
    "\n",
    "for i, urls in enumerate(test_df):\n",
    "    for url in urls:\n",
    "        r = requests.get(url, stream=True).raw\n",
    "        image = np.asarray(bytearray(r.read()), dtype=\"uint8\")\n",
    "        image = cv.imdecode(image, cv.IMREAD_COLOR)\n",
    "\n",
    "        if (image is not None):\n",
    "            val_x.append(image)\n",
    "            val_y.append(i)\n",
    "\n",
    "            plt.imshow(image)\n",
    "            plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rows = 5\n",
    "cols = 3\n",
    "\n",
    "fig = plt.figure(figsize=(25, 25))\n",
    "\n",
    "for i, j in enumerate(zip(val_x, val_y)):  # i - for subplots\n",
    "    orig = j[0]  # Original, not resized image\n",
    "    label = j[1]  # Label for that image\n",
    "    print(label)\n",
    "\n",
    "    image = cv.resize(orig, (96, 96))  # Resizing image to (96, 96)\n",
    "    image = image.reshape(-1, 96, 96, 3) / 255.0  # Reshape and scale resized image\n",
    "    this_model = load_model('app/model/model.hdf5')\n",
    "    preds = this_model.predict(image)  # Predicting image\n",
    "    pred_class = np.argmax(preds)  # Defining predicted class\n",
    "\n",
    "    true_label = f'True class: {combined[label]}'\n",
    "    pred_label = f'Predicted: {combined[pred_class]} {round(preds[0][pred_class] * 100, 2)}%'\n",
    "\n",
    "    fig.add_subplot(rows, cols, i + 1)\n",
    "    plt.imshow(orig[:, :, ::-1])\n",
    "    plt.title(f'{true_label}\\n{pred_label}:{pred_class}')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Is it possible to continue training a previously trained model? Yes!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "new_training = load_model('working/combined_model.hdf5')\n",
    "new_history = model.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=60, validation_data=[X_test, y_test],\n",
    "                        steps_per_epoch=len(X_train) // 32, callbacks=[checkpoint])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# How much did that improve the accuracy/loss?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot learning curves\n",
    "fig = plt.figure(figsize=(17, 4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(new_history.history['accuracy'], label='acc')\n",
    "plt.plot(new_history.history['val_accuracy'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(f'accuracy')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(new_history.history['loss'], label='loss')\n",
    "plt.plot(new_history.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(f'loss')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## About 10% accuracy improvement / negligable loss improvement"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Loading weights from best model\n",
    "model.load_weights('working/best_model_combined.hdf5')\n",
    "\n",
    "# Saving all model\n",
    "model.save('working/combined_model.hdf5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "datalore": {
   "base_environment": "default",
   "computation_mode": "REACTIVE",
   "package_manager": "pip",
   "packages": [
    {
     "name": "google",
     "source": "PIP",
     "version": "3.0.0"
    },
    {
     "name": "cloudstorage",
     "source": "PIP",
     "version": "0.11.0"
    },
    {
     "name": "tflite-model-maker",
     "source": "PIP"
    },
    {
     "name": "libusb",
     "source": "PIP",
     "version": "1.0.24b3"
    }
   ],
   "version": 1
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}